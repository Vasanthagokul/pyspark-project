{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating the connection with pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\spark-3.1.1-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "conf=pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc=pyspark.SparkContext(conf=conf)\n",
    "spark=SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightSchema = StructType([\n",
    "  StructField(\"DayofMonth\", IntegerType(), False),\n",
    "  StructField(\"DayOfWeek\", IntegerType(), False),\n",
    "  StructField(\"Carrier\", StringType(), False),\n",
    "  StructField(\"OriginAirportID\", IntegerType(), False),\n",
    "  StructField(\"DestAirportID\", IntegerType(), False),\n",
    "  StructField(\"DepDelay\", IntegerType(), False),\n",
    "  StructField(\"ArrDelay\", IntegerType(), False),\n",
    "])\n",
    "\n",
    "flights = spark.read.csv('dataset/raw-flight-data.csv', \n",
    "                         schema=flightSchema, header=True)\n",
    "flights.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+\n",
      "|airport_id|       city|state|                name|\n",
      "+----------+-----------+-----+--------------------+\n",
      "|     10165|Adak Island|   AK|                Adak|\n",
      "|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n",
      "|     10304|      Aniak|   AK|       Aniak Airport|\n",
      "|     10754|     Barrow|   AK|Wiley Post/Will R...|\n",
      "|     10551|     Bethel|   AK|      Bethel Airport|\n",
      "|     10926|    Cordova|   AK|Merle K Mudhole S...|\n",
      "|     14709|  Deadhorse|   AK|   Deadhorse Airport|\n",
      "|     11336| Dillingham|   AK|  Dillingham Airport|\n",
      "|     11630|  Fairbanks|   AK|Fairbanks Interna...|\n",
      "|     11997|   Gustavus|   AK|    Gustavus Airport|\n",
      "+----------+-----------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportSchema = StructType([\n",
    "  StructField(\"airport_id\", IntegerType(), False),\n",
    "  StructField(\"city\", StringType(), False),\n",
    "  StructField(\"state\", StringType(), False),\n",
    "  StructField(\"name\", StringType(), False),\n",
    "])\n",
    "\n",
    "airports = spark.read.csv('dataset/airports.csv', header=True, \n",
    "                          schema=airportSchema)\n",
    "airports.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Merge two dataFrame (flight and airports), and show how many flights from each City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          city|count|\n",
      "+--------------+-----+\n",
      "|       Phoenix|90281|\n",
      "|         Omaha|13537|\n",
      "|Raleigh/Durham|28436|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsByOrigin = flights.join(airports,\n",
    "                               flights.OriginAirportID == \n",
    "                               airports.airport_id).groupBy(\"city\").count()\n",
    "flightsByOrigin.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Removing Duplicate data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of original data rows:  2719418\n",
      "number of data rows after deleting duplicated data:  2696983\n",
      "number of duplicated data:  22435\n"
     ]
    }
   ],
   "source": [
    "#count the number of original data rows\n",
    "n1 = flights.count()\n",
    "print(\"number of original data rows: \", n1)\n",
    "#count the number of data rows after deleting duplicated data\n",
    "n2 = flights.dropDuplicates().count()\n",
    "print(\"number of data rows after deleting duplicated data: \", n2)\n",
    "n3 = n1 - n2\n",
    "print(\"number of duplicated data: \", n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2696983\n"
     ]
    }
   ],
   "source": [
    "flights =  flights.dropDuplicates()\n",
    "n4 = flights.count()\n",
    "print(n4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Duplicate entries successively removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Handline missing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|         0|        0|      0|              0|            0|   22209|   23798|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in flights.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing value rows:  46233\n"
     ]
    }
   ],
   "source": [
    "flightsNoMissingValue = flights.dropna(\n",
    "    how=\"any\", subset=[\"ArrDelay\", \"DepDelay\"])# use how=\"all\" for all column missing data\n",
    "numberOfMissingValueAny = n1 - flightsNoMissingValue.count()\n",
    "\n",
    "print(\"number of missing value rows: \", numberOfMissingValueAny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean ArrDelay:  6.7272897311633875\n",
      "mean DepDelay:  10.618575625454712\n",
      "+------------------+\n",
      "|     avg(ArrDelay)|\n",
      "+------------------+\n",
      "|6.7272897311633875|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#take mean value\n",
    "meanArrDelay = flights.groupBy().avg(\"ArrDelay\").take(1)[0][0]\n",
    "print(\"mean ArrDelay: \", meanArrDelay)\n",
    "meanDepDelay = flights.groupBy().avg(\"DepDelay\").take(1)[0][0]\n",
    "print(\"mean DepDelay: \", meanDepDelay)\n",
    "#drop duplicated data and fill missing data with mean value\n",
    "flightsCleanData=flights.fillna(\n",
    "    {'ArrDelay': meanArrDelay, 'DepDelay': meanDepDelay})\n",
    "#just for experiment\n",
    "flights.groupBy().avg(\"ArrDelay\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|         0|        0|      0|              0|            0|       0|       0|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsCleanData.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in flightsCleanData.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Successively replaced the null values with the means of the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ we have removed any duplicate entries and also handled missing entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Displaying cleaned data and its statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|         2|        1|     WN|          12889|        10140|      -1|       7|\n",
      "|         6|        1|     WN|          10821|        10140|       1|     -22|\n",
      "|         8|        1|     AA|          11298|        10140|       0|       6|\n",
      "|         8|        1|     MQ|          12892|        10140|       0|       9|\n",
      "|        15|        1|     WN|          11259|        10140|      21|      20|\n",
      "|        15|        1|     WN|          14747|        10140|      -6|       3|\n",
      "|        17|        1|     WN|          12889|        10140|      -4|      -9|\n",
      "|        19|        1|     EV|          12266|        10140|      -5|     -15|\n",
      "|        21|        1|     AA|          11298|        10140|      63|      54|\n",
      "|        26|        1|     DL|          10397|        10140|      -5|     -30|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsCleanData.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|          DepDelay|          ArrDelay|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           2696983|           2696983|\n",
      "|   mean|10.613481805409972|  6.72087217457433|\n",
      "| stddev| 36.04900147972999|38.578791794541594|\n",
      "|    min|               -63|               -94|\n",
      "|    max|              1863|              1845|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsCleanData.describe('DepDelay','ArrDelay').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+------------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|carrierIndex|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+------------+\n",
      "|         2|        1|     WN|          12889|        10140|      -1|       7|         0.0|\n",
      "|         6|        1|     WN|          10821|        10140|       1|     -22|         0.0|\n",
      "|         8|        1|     AA|          11298|        10140|       0|       6|         2.0|\n",
      "|         8|        1|     MQ|          12892|        10140|       0|       9|         8.0|\n",
      "|        15|        1|     WN|          11259|        10140|      21|      20|         0.0|\n",
      "|        15|        1|     WN|          14747|        10140|      -6|       3|         0.0|\n",
      "|        17|        1|     WN|          12889|        10140|      -4|      -9|         0.0|\n",
      "|        19|        1|     EV|          12266|        10140|      -5|     -15|         6.0|\n",
      "|        21|        1|     AA|          11298|        10140|      63|      54|         2.0|\n",
      "|        26|        1|     DL|          10397|        10140|      -5|     -30|         1.0|\n",
      "|        27|        1|     AA|          11298|        10140|     113|     117|         2.0|\n",
      "|        28|        1|     AA|          11298|        10140|      -3|       2|         2.0|\n",
      "|         3|        2|     WN|          12191|        10140|      -3|     -19|         0.0|\n",
      "|         4|        2|     WN|          12191|        10140|      51|      55|         0.0|\n",
      "|         7|        2|     OO|          12266|        10140|      -3|     -11|         5.0|\n",
      "|         8|        2|     MQ|          12892|        10140|      17|      25|         8.0|\n",
      "|        13|        2|     WN|          13796|        10140|      -2|     -11|         0.0|\n",
      "|        15|        2|     WN|          12889|        10140|      -2|     -15|         0.0|\n",
      "|        22|        2|     WN|          11259|        10140|       3|      -3|         0.0|\n",
      "|        25|        2|     OO|          14869|        10140|      -2|       2|         5.0|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer #this is used to label encode our data\n",
    "indexer = StringIndexer(inputCol=\"Carrier\", outputCol=\"carrierIndex\")\n",
    "encodedFlightData =  indexer.fit(flightsCleanData).transform(flightsCleanData)\n",
    "encodedFlightData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ As shown above the last column is an encoded version of the Carrier column\n",
    "+ now we will drop the column with string values and display the **Cleaned Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------------+-------------+--------+--------+------------+\n",
      "|DayofMonth|DayOfWeek|OriginAirportID|DestAirportID|DepDelay|ArrDelay|carrierIndex|\n",
      "+----------+---------+---------------+-------------+--------+--------+------------+\n",
      "|         2|        1|          12889|        10140|      -1|       7|         0.0|\n",
      "|         6|        1|          10821|        10140|       1|     -22|         0.0|\n",
      "|         8|        1|          11298|        10140|       0|       6|         2.0|\n",
      "|         8|        1|          12892|        10140|       0|       9|         8.0|\n",
      "|        15|        1|          11259|        10140|      21|      20|         0.0|\n",
      "+----------+---------+---------------+-------------+--------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FinalCleanedFlightData = encodedFlightData.drop(\"Carrier\")\n",
    "FinalCleanedFlightData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ For our classification problem we will need a target column so we shall classify the flight as late if ArrDelay>15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------------+-------------+--------+------------+----+\n",
      "|DayofMonth|DayOfWeek|OriginAirportID|DestAirportID|DepDelay|carrierIndex|Late|\n",
      "+----------+---------+---------------+-------------+--------+------------+----+\n",
      "|         2|        1|          12889|        10140|      -1|         0.0|   0|\n",
      "|         6|        1|          10821|        10140|       1|         0.0|   0|\n",
      "|         8|        1|          11298|        10140|       0|         2.0|   0|\n",
      "|         8|        1|          12892|        10140|       0|         8.0|   0|\n",
      "|        15|        1|          11259|        10140|      21|         0.0|   1|\n",
      "+----------+---------+---------------+-------------+--------+------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Flightdata = FinalCleanedFlightData.select(\n",
    "    \"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \n",
    "    \"DepDelay\",\"carrierIndex\", ((col(\"ArrDelay\") > 15).cast(\"Int\").alias(\"Late\")))\n",
    "Flightdata.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "+ the OriginalAirportID and DestAirportID are very large values so this might hinder training so I am going to scale them down to make it easier to work with for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the maximum of the column 'OriginAirportID': \n",
      "+--------------------+\n",
      "|max(OriginAirportID)|\n",
      "+--------------------+\n",
      "|               15376|\n",
      "+--------------------+\n",
      "\n",
      "This is the minimum of the column 'OriginAirportID': \n",
      "+--------------------+\n",
      "|min(OriginAirportID)|\n",
      "+--------------------+\n",
      "|               10140|\n",
      "+--------------------+\n",
      "\n",
      "This is the maximum of the column 'OriginAirportID': \n",
      "+------------------+\n",
      "|max(DestAirportID)|\n",
      "+------------------+\n",
      "|             15376|\n",
      "+------------------+\n",
      "\n",
      "This is the minimum of the column 'OriginAirportID': \n",
      "+------------------+\n",
      "|min(DestAirportID)|\n",
      "+------------------+\n",
      "|             10140|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the maximum of the column 'OriginAirportID': \")\n",
    "Flightdata.agg({'OriginAirportID':'max'}).show()\n",
    "\n",
    "print(\"This is the minimum of the column 'OriginAirportID': \")\n",
    "Flightdata.agg({'OriginAirportID':'min'}).show()\n",
    "\n",
    "print(\"This is the maximum of the column 'OriginAirportID': \")\n",
    "Flightdata.agg({'DestAirportID':'max'}).show()\n",
    "\n",
    "print(\"This is the minimum of the column 'OriginAirportID': \")\n",
    "Flightdata.agg({'DestAirportID':'min'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ I am going to perform minmax normalization scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------------+-------------+--------+------------+----+-------------------+-----------------+----------------------+--------------------+\n",
      "|DayofMonth|DayOfWeek|OriginAirportID|DestAirportID|DepDelay|carrierIndex|Late|OriginAirportID_vec|DestAirportID_vec|OriginAirportID_scaled|DestAirportID_scaled|\n",
      "+----------+---------+---------------+-------------+--------+------------+----+-------------------+-----------------+----------------------+--------------------+\n",
      "|         2|        1|          12889|        10140|      -1|         0.0|   0|          [12889.0]|        [10140.0]|  [0.5250190985485103]|               [0.0]|\n",
      "|         6|        1|          10821|        10140|       1|         0.0|   0|          [10821.0]|        [10140.0]|   [0.130061115355233]|               [0.0]|\n",
      "|         8|        1|          11298|        10140|       0|         2.0|   0|          [11298.0]|        [10140.0]|  [0.22116119174942...|               [0.0]|\n",
      "|         8|        1|          12892|        10140|       0|         8.0|   0|          [12892.0]|        [10140.0]|  [0.5255920550038197]|               [0.0]|\n",
      "|        15|        1|          11259|        10140|      21|         0.0|   1|          [11259.0]|        [10140.0]|  [0.2137127578304049]|               [0.0]|\n",
      "+----------+---------+---------------+-------------+--------+------------+----+-------------------+-----------------+----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "columns_to_scale = [\"OriginAirportID\", \"DestAirportID\"]\n",
    "assemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in columns_to_scale]\n",
    "scalers = [MinMaxScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in columns_to_scale]\n",
    "pipeline = Pipeline(stages=assemblers + scalers)\n",
    "scalerModel = pipeline.fit(Flightdata)\n",
    "scaledFlightData = scalerModel.transform(Flightdata)\n",
    "scaledFlightData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Dropping all the unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------------------+--------------------+--------+------------+----+\n",
      "|DayofMonth|DayOfWeek|OriginAirportID_scaled|DestAirportID_scaled|DepDelay|carrierIndex|Late|\n",
      "+----------+---------+----------------------+--------------------+--------+------------+----+\n",
      "|         2|        1|  [0.5250190985485103]|               [0.0]|      -1|         0.0|   0|\n",
      "|         6|        1|   [0.130061115355233]|               [0.0]|       1|         0.0|   0|\n",
      "|         8|        1|  [0.22116119174942...|               [0.0]|       0|         2.0|   0|\n",
      "|         8|        1|  [0.5255920550038197]|               [0.0]|       0|         8.0|   0|\n",
      "|        15|        1|  [0.2137127578304049]|               [0.0]|      21|         0.0|   1|\n",
      "+----------+---------+----------------------+--------------------+--------+------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FinalFlightData = scaledFlightData.select(\n",
    "    \"DayofMonth\", \"DayOfWeek\", \"OriginAirportID_scaled\", \"DestAirportID_scaled\", \n",
    "    \"DepDelay\",\"carrierIndex\",\"Late\")\n",
    "FinalFlightData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We can see in the above scaled columns the ID has remained unique even after scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Statistical Summaries on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+----+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|Late|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+----+\n",
      "|         2|        1|     WN|          12889|        10140|      -1|       7|   0|\n",
      "|         6|        1|     WN|          10821|        10140|       1|     -22|   0|\n",
      "|         8|        1|     AA|          11298|        10140|       0|       6|   0|\n",
      "|         8|        1|     MQ|          12892|        10140|       0|       9|   0|\n",
      "|        15|        1|     WN|          11259|        10140|      21|      20|   1|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "StatsFlightData = flightsCleanData.select(\n",
    "    \"DayofMonth\", \"DayOfWeek\",\"Carrier\",\"OriginAirportID\", \"DestAirportID\", \n",
    "    \"DepDelay\",\"ArrDelay\", ((col(\"ArrDelay\") > 15).cast(\"Int\").alias(\"Late\")))\n",
    "StatsFlightData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Some Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCount(series):\n",
    "    '''\n",
    "       Takes in a series as input and returns the unique attributes along with its percentage\n",
    "       \n",
    "       Input:\n",
    "           pandas series\n",
    "       \n",
    "       Output:\n",
    "           X: Unique attributes in the series Y: % of unique attributes in the series\n",
    "    '''\n",
    "    count = series.value_counts()\n",
    "    xValues = count.index\n",
    "    yPercent = (count/count.sum())*100\n",
    "    return xValues, yPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myPlot(x,y,xLable,yLable,title,figsize,type):\n",
    "    '''\n",
    "        Takes in the series of data x and y along with the XLables, YLables, Title, Figure Size and Type of the chart to plot and plots the chart\n",
    "        \n",
    "        Input:\n",
    "            x -> pandas series\n",
    "            y -> pandas series\n",
    "            XLable -> string corresponding to the lable for X Axis\n",
    "            YLable -> string corresponding to the lable for Y Axis\n",
    "            Title -> string corresponding to the Title of the graph\n",
    "            Figure Size -> Size of the intended graph\n",
    "            Type -> chart type\n",
    "        Output:\n",
    "            Plots the graph\n",
    "    '''\n",
    "    sns.set_style('whitegrid')\n",
    "    fig,axes = plt.subplots(figsize=figsize)\n",
    "    axes.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "    axes.set_xlabel(xLable)\n",
    "    axes.set_ylabel(yLable)\n",
    "    if(title!=None):\n",
    "        axes.set_title(title)\n",
    "    if(type=='bar'):\n",
    "        sns.barplot(x=x,y=y,ax=axes)\n",
    "    if(type=='line'):\n",
    "        sns.lineplot(x=x,y=y,ax=axes,sort=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Converting to pandas so it becomes easier to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as df\n",
    "pandasDF = StatsFlightData.toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
